{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCAVS_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "CSsSeN04_vIw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PC-AVS  Pose-Controllable Audio-Visual System Colab\n",
        "\n",
        "[Watch this video to guide you through the process](https://www.youtube.com/watch?v=4O3EqIiEzKQ&ab_channel=bycloudump)\n",
        "\n",
        "Original code : [visit here](https://github.com/Hangz-nju-cuhk/Talking-Face_PC-AVS)\n",
        "\n",
        "This notebook was put together by [BibbyBob](https://github.com/BibbyBoisGitHub) and [justinjohn-03](https://github.com/justinjohn0306)"
      ],
      "metadata": {
        "id": "_Aa7dKdZugx9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrA0wfugkDoa",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown # Checks your GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### Download the code and install the dependencies\n",
        "!git clone https://github.com/bycloudai/PCAVS-Windows\n",
        "%cd /content/PCAVS-Windows\n",
        "!pip install git+https://github.com/wkentaro/gdown.git\n",
        "!pip install face-alignment\n",
        "!pip install -r requirements.txt\n",
        "!pip install lws"
      ],
      "metadata": {
        "id": "EcK914BQ8dRe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Patch** (run only once)"
      ],
      "metadata": {
        "id": "CSsSeN04_vIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/PCAVS-Windows/scripts/align_68.py\n",
        "import face_alignment\n",
        "import os\n",
        "import cv2\n",
        "import skimage.transform as trans\n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "def get_affine(src):\n",
        "    dst = np.array([[87,  59],\n",
        "                    [137,  59],\n",
        "                    [112, 120]], dtype=np.float32)\n",
        "    tform = trans.SimilarityTransform()\n",
        "    tform.estimate(src, dst)\n",
        "    M = tform.params[0:2, :]\n",
        "    return M\n",
        "\n",
        "\n",
        "def affine_align_img(img, M, crop_size=224):\n",
        "    warped = cv2.warpAffine(img, M, (crop_size, crop_size), borderValue=0.0)\n",
        "    return warped\n",
        "\n",
        "\n",
        "def affine_align_3landmarks(landmarks, M):\n",
        "    new_landmarks = np.concatenate([landmarks, np.ones((3, 1))], 1)\n",
        "    affined_landmarks = np.matmul(new_landmarks, M.transpose())\n",
        "    return affined_landmarks\n",
        "\n",
        "\n",
        "def get_eyes_mouths(landmark):\n",
        "    three_points = np.zeros((3, 2))\n",
        "    three_points[0] = landmark[36:42].mean(0)\n",
        "    three_points[1] = landmark[42:48].mean(0)\n",
        "    three_points[2] = landmark[60:68].mean(0)\n",
        "    return three_points\n",
        "\n",
        "\n",
        "def get_mouth_bias(three_points):\n",
        "    bias = np.array([112, 120]) - three_points[2]\n",
        "    return bias\n",
        "\n",
        "\n",
        "def align_folder(folder_path, folder_save_path):\n",
        "\n",
        "    fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, device=device)\n",
        "    preds = fa.get_landmarks_from_directory(folder_path)\n",
        "\n",
        "    sumpoints = 0\n",
        "    three_points_list = []\n",
        "\n",
        "    for img in preds.keys():\n",
        "        pred_points = np.array(preds[img])\n",
        "        if pred_points is None or len(pred_points.shape) != 3:\n",
        "            print('preprocessing failed')\n",
        "            return False\n",
        "        else:\n",
        "            num_faces, size, _ = pred_points.shape\n",
        "            if num_faces == 1 and size == 68:\n",
        "\n",
        "                three_points = get_eyes_mouths(pred_points[0])\n",
        "                sumpoints += three_points\n",
        "                three_points_list.append(three_points)\n",
        "            else:\n",
        "\n",
        "                print('preprocessing failed')\n",
        "                return False\n",
        "    avg_points = sumpoints / len(preds)\n",
        "    M = get_affine(avg_points)\n",
        "    p_bias = None\n",
        "    for i, img_pth in enumerate(preds.keys()):\n",
        "        three_points = three_points_list[i]\n",
        "        affined_3landmarks = affine_align_3landmarks(three_points, M)\n",
        "        bias = get_mouth_bias(affined_3landmarks)\n",
        "        if p_bias is None:\n",
        "            bias = bias\n",
        "        else:\n",
        "            bias = p_bias * 0.2 + bias * 0.8\n",
        "        p_bias = bias\n",
        "        M_i = M.copy()\n",
        "        M_i[:, 2] = M[:, 2] + bias\n",
        "        img = cv2.imread(img_pth)\n",
        "        wrapped = affine_align_img(img, M_i)\n",
        "        img_save_path = os.path.join(folder_save_path, img_pth.split('/')[-1])\n",
        "        cv2.imwrite(img_save_path, wrapped)\n",
        "    print('cropped files saved at {}'.format(folder_save_path))\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--folder_path', help='the folder which needs processing')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if os.path.isdir(args.folder_path):\n",
        "        home_path = '/'.join(args.folder_path.split('/')[:-1])\n",
        "        save_img_path = os.path.join(home_path, args.folder_path.split('/')[-1] + '_cropped')\n",
        "        os.makedirs(save_img_path, exist_ok=True)\n",
        "\n",
        "        align_folder(args.folder_path, save_img_path)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "JX0GLOpR_hAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Process**"
      ],
      "metadata": {
        "id": "wsbitVTlAFlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #### Download the checkpoints and unzip them\n",
        "import gdown\n",
        "!gdown 1Zehr3JLIpzdg2S5zZrhIbpYPKF-4gKU_\n",
        "!unzip demo.zip -d /content/PCAVS-Windows/checkpoints"
      ],
      "metadata": {
        "id": "ZU4Il3EE8iXa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #### Unzips the misc files in misc folder \n",
        "!unzip /content/PCAVS-Windows/misc/Audio_Source.zip -d /content/PCAVS-Windows/misc/\n",
        "!rm /content/PCAVS-Windows/misc/Audio_Source.zip\n",
        "!unzip /content/PCAVS-Windows/misc/Input.zip -d /content/PCAVS-Windows/misc/\n",
        "!rm /content/PCAVS-Windows/misc/Input.zip\n",
        "!unzip /content/PCAVS-Windows/misc/Mouth_Source.zip -d /content/PCAVS-Windows/misc/\n",
        "!rm /content/PCAVS-Windows/misc/Mouth_Source.zip\n",
        "!unzip /content/PCAVS-Windows/misc/Pose_Source.zip -d /content/PCAVS-Windows/misc/\n",
        "!rm /content/PCAVS-Windows/misc/Pose_Source.zip\n",
        "%cd /content/PCAVS-Windows"
      ],
      "metadata": {
        "cellView": "form",
        "id": "49sdzgmjxr9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### This cell extracts the frames from the video\n",
        "#@markdown make sure to create the folder and edit this cell accodringly before running\n",
        "!ffmpeg -i misc/Pose_Source/trump.mp4 -vf fps=24 misc/Pose_Source/trump/%06d.jpg"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kzCdRZ278sPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The cells below will align the frames extracted from both the video and image \n",
        "(the longer the video is, the longer the process)"
      ],
      "metadata": {
        "id": "bd0uyikRuTVy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/align_68.py --folder_path misc/Input/biden"
      ],
      "metadata": {
        "id": "-nOdtF6F8t7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/align_68.py --folder_path misc/Pose_Source/trump"
      ],
      "metadata": {
        "id": "BkZpwAON-1uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This is the final cell that you have to run, after editing the ``demo.csv`` file, run the cell below and get the results in the ``results`` folder."
      ],
      "metadata": {
        "id": "FDqe0KMzuZ5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py --name demo --meta_path_vox misc/demo.csv --netG modulate --netA resseaudio --netA_sync ressesync --netD multiscale --netV resnext --netE fan --model av --gpu_ids 0 --clip_len 1 --batchSize 16 --style_dim 2560 --nThreads 4 --input_id_feature --generate_interval 1 --style_feature_loss --use_audio 1 --noise_pose --gen_video --driving_pose --generate_from_audio_only"
      ],
      "metadata": {
        "id": "JAPRi6O48x3f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}